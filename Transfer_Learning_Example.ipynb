{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6uOfRzgAOal"
   },
   "source": [
    "# Building an Image Classifier in Five Minutes\n",
    "\n",
    "A common machine learning task is called **image classification**, where the system tries to recognize and label what it sees.   For example, a self-driving car needs to identify things that it sees in its environment, such as other cars, pedestrians and road signs.\n",
    "\n",
    "Researchers have created and shared machine learning models that are good at recognizing many different categories of objects in images.  These models can be easily re-purposed to recognize a new set of categories through a process called **transfer learning.**  \n",
    "\n",
    "In this notebook, we will apply transfer learning to re-purpose a machine learning model called a **neural network** to recognize cats and dogs in images.  To teach the model how to categorize images, we need to provide the model with a collection of labeled example images.  Once the model is \"trained\" to label these example images correctly, it will be able to accurately label any new, unseen images that you give it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXpBYNmKDsRC"
   },
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "Here we download and extract a collection of several hundred images of cats and dogs.  The images are organized into a specific directory structure.  The cat images are under `oxford_pets_cat_dog/train/cat` and the dog images are under `oxford_pets_cat_dog/train/dog`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utkWd3zVdAEc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('oxford_pets_cat_dog_small.zip'):\n",
    "  !wget \"https://www.dropbox.com/s/pps8tui39ctkha5/oxford_pets_cat_dog_small.zip?dl=1\" -O oxford_pets_cat_dog_small.zip\n",
    "  !unzip -q oxford_pets_cat_dog_small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyEeJW4qEqPz"
   },
   "source": [
    "We specify the path to the dataset in the variable `DATASET_PATH` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYDALrP6k9Xw"
   },
   "outputs": [],
   "source": [
    "#@title Configuration\n",
    "\n",
    "DATASET_PATH = 'oxford_pets_cat_dog_small' #@param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGztCYS3EyGY"
   },
   "source": [
    "This code grabs the names of the class labels from the directory structure.  We will use these class names later when we ask the model to classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4qgqMPHER1W"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "CLASS_LABELS = ','.join(os.path.basename(dir) for dir in sorted(glob.glob(os.path.join(DATASET_PATH,'train','*'))))\n",
    "print(\"Class labels:\",CLASS_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWxnRadLE6Jf"
   },
   "source": [
    "## Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rysmvQcVme6i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "!pip install wget\n",
    "import wget\n",
    "import imageio\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICpgpWTxAj3_"
   },
   "source": [
    "### Loading the pre-trained neural network\n",
    "\n",
    "Keras provides many different pre-trained networks.  Here we load a VGG16 network pre-trained on ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TKMi61_ml8v"
   },
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.VGG16(include_top=True, weights='imagenet',input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV4dIf-GAsew"
   },
   "source": [
    "The model summary displays the sequence of layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAhaJFg1mvih"
   },
   "outputs": [],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J69M9qmDAwj7"
   },
   "source": [
    "This model has been trained to predict 1,000 different object categories.  This is why the last layer has 1000 outputs -- one number for each class.  The class with the highest number is the class chosen by the network for the input image.\n",
    "\n",
    "We want to re-purpose this model to output two classes.  So, we will remove the last layer and replace it with something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QLKTN46myIr"
   },
   "outputs": [],
   "source": [
    "vgg_features = tf.keras.Model(inputs=vgg.input,outputs=vgg.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BJMkw-zphGi"
   },
   "outputs": [],
   "source": [
    "vgg_features.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsR2f3TmA7LD"
   },
   "source": [
    "### Dataset preparation\n",
    "\n",
    "Now we will load the dataset and set it up as a Tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItCbYlYk2Fsb"
   },
   "outputs": [],
   "source": [
    "builder = tfds.folder_dataset.ImageFolder(DATASET_PATH)\n",
    "train_ds = builder.as_dataset(split='train', shuffle_files=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zni6JG5UFiyN"
   },
   "source": [
    "Here you can see some examples from the dataset with their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3KYu8LlBdKr"
   },
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(train_ds, builder.info)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCueg3kWqnO-"
   },
   "source": [
    "We add some processing steps to the dataset:\n",
    "* Resize images to 224x224\n",
    "* Preprocess images using the VGG16 preprocess_input() function provided by Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnTSP-ZlB-N9"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda x: {'image':tf.image.resize(x['image'],[224,224]),'label':x['label']})\n",
    "train_ds = train_ds.map(lambda x: {'image':tf.keras.applications.vgg16.preprocess_input(x['image']),'label':x['label']})\n",
    "train_ds = train_ds.batch(32)\n",
    "train_ds = train_ds.prefetch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMK-T-I8Bwwp"
   },
   "source": [
    "### Extracting deep features\n",
    "\n",
    "Now we run the images through the VGG network to extract a 4096-dim vector for each image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvys_-gzCpbK"
   },
   "outputs": [],
   "source": [
    "train_features = vgg_features.predict(train_ds.map(lambda x: x['image']),verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSN1ifQsB5fe"
   },
   "source": [
    "We also put the labels into a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hykenrExrgd"
   },
   "outputs": [],
   "source": [
    "train_labels = np.concatenate([y for y in train_ds.map(lambda x: x['label'])],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twne0Stfq3mT"
   },
   "source": [
    "Now we have a 4096-dimensional feature vector an integer label for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUZo6btwx6ce"
   },
   "outputs": [],
   "source": [
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQC1BvClB-W6"
   },
   "source": [
    "### Transfer learning\n",
    "\n",
    "Now we can train a classifier called a **support vector machine** on our feature vectors and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YA3qdKUSFaNB"
   },
   "outputs": [],
   "source": [
    "import sklearn.svm\n",
    "classifier = sklearn.svm.SVC().fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8u9Wo-bSrJvY"
   },
   "source": [
    "Let's evaluate on the training set to see how we did.\n",
    "\n",
    "**Accuracy** means the percentage of images that the classifier correctly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTitYJvxxwPw"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_preds = classifier.predict(train_features)\n",
    "acc = accuracy_score(train_labels,train_preds)\n",
    "print(f'Accuracy: {acc*100}\\%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r0CyAR6CaMW"
   },
   "source": [
    "Our model classifies over 99% of the dataset correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cChwOKoyld0i"
   },
   "source": [
    "# Testing on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D67ArRGyKyc"
   },
   "source": [
    "Now you can provide a new image to the classifier, and it will say what it thinks is in the image.\n",
    "\n",
    "Find the URL for an image of a dog and paste it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKngAxb4lvLP"
   },
   "outputs": [],
   "source": [
    "TEST_IMAGE_URL = 'https://i.natgeofe.com/n/46b07b5e-1264-42e1-ae4b-8a021226e2d0/domestic-cat_thumb_square.jpg' #@param {type: 'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gg_WzjG82DBK"
   },
   "outputs": [],
   "source": [
    "filename = wget.download(TEST_IMAGE_URL)\n",
    "\n",
    "import imageio\n",
    "image = imageio.imread(filename)\n",
    "images = image[None,...]\n",
    "\n",
    "images_resized = tf.image.resize(images,[224,224])\n",
    "images_pre = tf.keras.applications.vgg16.preprocess_input(images_resized)\n",
    "\n",
    "features = vgg_features.predict(images_pre)\n",
    "preds = classifier.predict(features)\n",
    "\n",
    "class_labels = CLASS_LABELS.split(',')\n",
    "pred_label = class_labels[preds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocfrdyDSrZQD"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.title(f'classification: {pred_label}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3-UGFojHg9W"
   },
   "source": [
    "# Experiment\n",
    "\n",
    "Now it's your turn!  Make your own dataset and train the image classifier to recognize objects in it.\n",
    "\n",
    "You should first make a copy of this notebook so that you can save your changes.  Go to File > Save a Copy in Drive.\n",
    "\n",
    "Then, connect to Google Drive using the button in the \"Files\" panel on the left.  Pick two categories and assemble a small dataset of images in the proper directory structure in your Google Drive.  For example, you could find ten pictures of apples and ten pictures of oranges using [Google Images](https://images.google.com/), and put them into directories called \"fruits/train/apple\" and \"fruits/train/orange\".\n",
    "\n",
    "Set the `DATASET_PATH` variable to the location of your dataset on Google Drive (e.g. `drive/MyDrive/fruits`) and run through the notebook.  In the last step, provide the URL of a new image that wasn't included in your training set.  Does the model properly recognize the image?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mqg-u70RISBQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SLOHS Transfer Learning Example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
